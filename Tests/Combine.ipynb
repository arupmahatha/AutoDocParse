{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shipper Name: MILEAGE LOGISTICS PRIVATE LIMITED\\nConsignee Name: ELECTRONICS MARITIME PRIVATE LIMITED\\nInvoice Number: NA\\nDate: 03/06/2023\\nPayment Terms: Freight Prepaid\\nCurrency: INR\\nDue Date: NA\\nItems: SUB-MARINE SURVEY EQUIPMENT\\nQuantities: 14\\nUnit Price: AS AGREED\\nTotal Amount: AS AGREED']\n",
      "CSV file for HAWB.pdf GPT output saved: /Users/arup/Documents/Test/CSV/HAWB_GPT_Output.csv\n",
      "Average Processing Time for classified files: 10.288441181182861 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# Initialize the OpenAI client outside the function\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "# Function to clean the output folder before generating new images\n",
    "def clean_output_folder(output_folder):\n",
    "    file_list = glob.glob(os.path.join(output_folder, '*'))\n",
    "    for file_path in file_list:\n",
    "        os.remove(file_path)\n",
    "\n",
    "# Function to convert PDF to images\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    file_name = os.path.basename(pdf_path)\n",
    "    file_name_no_extension = os.path.splitext(file_name)[0]\n",
    "    \n",
    "    images = convert_from_path(pdf_path, output_folder=output_folder, fmt='png')\n",
    "\n",
    "    if len(images) == 1:  # Check if only one page in the PDF\n",
    "        image_path = os.path.join(output_folder, f\"{file_name_no_extension}_page_1.png\")\n",
    "        images[0].save(image_path, \"PNG\")\n",
    "        return [image_path]\n",
    "\n",
    "    # Save images with expected filenames based on PDF name and page number\n",
    "    image_paths = []\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = os.path.join(output_folder, f\"{file_name_no_extension}_page_{i+1}.png\")\n",
    "        image.save(image_path, \"PNG\")  # Save the image with the expected filename\n",
    "        image_paths.append(image_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Function to extract text from an image using pytesseract\n",
    "def extract_text_from_image(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "        return pytesseract.image_to_string(image_path)\n",
    "    else:\n",
    "        print(f\"Error: File not found at path: {image_path}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to process text and classify based on regex patterns\n",
    "def process_text(extracted_text):\n",
    "    # Define regex patterns\n",
    "    invoice_pattern = r'\\b(Commercial\\sInvoice|Invoice)\\b'\n",
    "    permit_pattern = r'\\bCARGO\\sCLEARANCE\\sPERMIT\\b'\n",
    "    packaging_list_pattern = r'\\bPACKING\\sLIST\\b'\n",
    "    bill_of_lading_pattern = r'\\bBILL\\sOF\\sLADING\\b'\n",
    "    \n",
    "    output_data = {}\n",
    "\n",
    "    if re.search(invoice_pattern, extracted_text, re.IGNORECASE):\n",
    "        output_data['FileType'] = 'Invoice'\n",
    "        output_data['Prompt'] = \"Strictly output only and only a list of key-value pairs from the document. Keys are: Customer name, Destination name, Invoice number, Date, Payment terms, Currency, Due date, items, quantities, unit price, total amount. For a key for which no value is extracted - return value as NA.\"\n",
    "    elif re.search(permit_pattern, extracted_text, re.IGNORECASE):\n",
    "        output_data['FileType'] = 'Permit'\n",
    "        output_data['Prompt'] = \"Strictly output only and only a list of key-value pairs from the document. Keys are: permit number, importer details, exporter details, arrival date, departure date, and license number. For a key for which no value is extracted - return value as NA.\"\n",
    "    elif re.search(packaging_list_pattern, extracted_text, re.IGNORECASE):\n",
    "        output_data['FileType'] = 'Packaging List'\n",
    "        output_data['Prompt'] = \"Strictly output only and only a list of key-value pairs from the document. Keys are:  item and no of cartons. For a key for which no value is extracted - return value as NA.\"\n",
    "    elif re.search(bill_of_lading_pattern, extracted_text, re.IGNORECASE):\n",
    "        output_data['FileType'] = 'Bill Of Lading'\n",
    "        output_data['Prompt'] = \"Strictly output only and only a list of key-value pairs from the document. Keys are:  Bill number, port for release, shipper details, consignee details, port of loading, port of discharge, final destination, voyage number, and container number. For a key for which no value is extracted - return value as NA.\"\n",
    "    else:\n",
    "        output_data['FileType'] = 'Unknown'\n",
    "        output_data['Prompt'] = \"Strictly output only and only a list of key-value pairs from the document. If document is an invoice, keys are: Customer name, Destination name, Invoice number, Date, Payment terms, Currency, Due date, items, quantities, unit price, total amount. If it is a Bill of Lading list, keys are: Bill number, port for release, shipper details, consignee details, port of loading, port of discharge, final destination, voyage number, and container number. If it is a permit, keys are: permit number, importer details, exporter details, arrival date, departure date, and license number. If it is a packaging list, keys are: item and no of cartons. For a key for which no value is extracted - return value as NA. If the type of document is not invoice/packaging list/bill of lading/permit, assume it is an invoice.\"\n",
    "\n",
    "    return output_data\n",
    "\n",
    "# Function to encode an image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Function to analyze images using OpenAI GPT\n",
    "def analyze_images(image_paths, openai_client, prompt):\n",
    "    base64_images = [encode_image(image_path) for image_path in image_paths]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{','.join(base64_images)}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return [resp.message.content for resp in response.choices]\n",
    "\n",
    "# Function to process PDF, extract text, classify, and further process using GPT\n",
    "def process_pdf(pdf_path, openai_client):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    images = convert_pdf_to_images(pdf_path, output_image_folder)\n",
    "    \n",
    "    extracted_text = \"\"\n",
    "    for image_path in images:\n",
    "        extracted_text += extract_text_from_image(image_path)\n",
    "    \n",
    "    classified_data = process_text(extracted_text)\n",
    "    \n",
    "    extracted_content = analyze_images(images, openai_client, classified_data['Prompt'])\n",
    "    classified_data['GPT_Response'] = extracted_content\n",
    "\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    classified_data['FileName'] = os.path.basename(pdf_path)\n",
    "    classified_data['ProcessingTime'] = processing_time\n",
    "\n",
    "    print(classified_data['GPT_Response'])\n",
    "    return classified_data\n",
    "\n",
    "def save_gpt_response_to_csv(gpt_response, output_file):\n",
    "    # Process and extract key-value pairs\n",
    "    extracted_data = {}\n",
    "    for item in gpt_response:\n",
    "        pairs = item.split('\\n')\n",
    "        for pair in pairs:\n",
    "            key_value = pair.split(':')\n",
    "            if len(key_value) == 2:\n",
    "                key = key_value[0].strip()\n",
    "                value = key_value[1].strip()\n",
    "                extracted_data[key] = value\n",
    "            else:\n",
    "                extracted_data['NA'] = pair.strip()  # If not in 'key: value' format, store it as 'NA'\n",
    "\n",
    "    # Writing extracted data to CSV\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Key', 'Value'])\n",
    "        for key, value in extracted_data.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "# Set your PDF directory path\n",
    "pdf_folder = '/Users/arup/Documents/Test/*.pdf'\n",
    "pdf_files = glob.glob(pdf_folder)\n",
    "\n",
    "output_image_folder = '/Users/arup/Documents/Test/Images/'  # Change this to your desired output folder\n",
    "\n",
    "# Inside the loop that processes each PDF file\n",
    "output_directory = '/Users/arup/Documents/Test/CSV/'  # Change this to your desired directory\n",
    "\n",
    "# List to hold processing times of classified PDFs\n",
    "classified_processing_times = []\n",
    "\n",
    "# Loop through PDFs, process and classify, and further process using GPT if classified\n",
    "for pdf_file in pdf_files:\n",
    "    clean_output_folder(output_image_folder)  # Clean the output folder before processing new PDF\n",
    "    \n",
    "    result = process_pdf(pdf_file, client)\n",
    "    all_outputs.append(result)\n",
    "\n",
    "    classified_processing_times.append(result['ProcessingTime'])\n",
    "\n",
    "    # Define the output file path for the GPT response CSV\n",
    "    output_file = os.path.join(output_directory, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_GPT_Output.csv')\n",
    "    \n",
    "    # Save the GPT response to CSV\n",
    "    save_gpt_response_to_csv(result['GPT_Response'], output_file)\n",
    "    \n",
    "    # Print a message indicating that the CSV file has been saved\n",
    "    print(f\"CSV file for {os.path.basename(pdf_file)} GPT output saved: {output_file}\")\n",
    "\n",
    "\n",
    "# Calculate and display average processing time for classified PDFs\n",
    "if classified_processing_times:\n",
    "    average_processing_time = sum(classified_processing_times) / len(classified_processing_times)\n",
    "    print(f\"Average Processing Time for classified files: {average_processing_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
